import { useState, useRef, useEffect, useCallback } from "react";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import { Mic, Square, Loader2, RotateCcw, Volume2 } from "lucide-react";
import { useToast } from "@/hooks/use-toast";
import ReadingService from "@/services/readingService";

interface RecorderProps {
  expectedText: string;
  onRecordingComplete?: (transcript: string, accuracy: number, wrongWords: string[]) => void;
}

// Check if Web Speech API is supported
const isSpeechRecognitionSupported = () => {
  return 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
};

// Type definitions for Web Speech API (not included in TypeScript by default)
interface SpeechRecognitionEvent {
  resultIndex: number;
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent {
  error: string;
}

interface SpeechRecognitionResultList {
  length: number;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  isFinal: boolean;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

export const Recorder = ({ expectedText, onRecordingComplete }: RecorderProps) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [interimTranscript, setInterimTranscript] = useState("");
  const [feedback, setFeedback] = useState<{
    accuracy: number;
    errors: string[];
    message: string;
    encouragement: string;
    highlightedText?: string;
  } | null>(null);
  const [sttMethod, setSttMethod] = useState<'web' | 'websocket'>('web');
  
  // Web Speech API refs
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const recognitionRef = useRef<any>(null);
  
  // WebSocket STT refs (fallback)
  const wsRef = useRef<WebSocket | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const canSendRef = useRef<boolean>(false);
  const confirmedTextRef = useRef<string>("");
  const partialTextRef = useRef<string>("");
  
  const { toast } = useToast();

  // Initialize Web Speech API
  useEffect(() => {
    if (isSpeechRecognitionSupported()) {
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const SpeechRecognitionClass = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
      recognitionRef.current = new SpeechRecognitionClass();
      recognitionRef.current.continuous = true;
      recognitionRef.current.interimResults = true;
      recognitionRef.current.lang = 'vi-VN'; // Vietnamese
      
      recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
        let interim = '';
        let final = '';
        
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcriptPart = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            final += transcriptPart + ' ';
          } else {
            interim += transcriptPart;
          }
        }
        
        if (final) {
          setTranscript(prev => (prev + ' ' + final).trim());
        }
        setInterimTranscript(interim);
      };

      recognitionRef.current.onerror = (event: SpeechRecognitionErrorEvent) => {
        console.error('Speech recognition error:', event.error);
        if (event.error === 'not-allowed') {
          // Toast handled elsewhere to avoid dependency issues
          console.error('Microphone permission denied');
        } else if (event.error === 'no-speech') {
          // Ignore no-speech errors during recording
        } else {
          console.error(`Speech recognition error: ${event.error}`);
          // Try WebSocket fallback
          setSttMethod('websocket');
        }
      };

      recognitionRef.current.onend = () => {
        // Auto-restart handled in startWebSpeechRecording
      };

      setSttMethod('web');
      console.log('âœ… Web Speech API initialized');
    } else {
      console.log('âš ï¸ Web Speech API not supported, using WebSocket');
      setSttMethod('websocket');
    }

    return () => {
      cleanupAll();
    };
  }, []);

  // Cleanup all resources
  const cleanupAll = () => {
    try {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      wsRef.current?.close();
      processorRef.current?.disconnect();
      sourceRef.current?.disconnect();
      audioCtxRef.current?.close();
      streamRef.current?.getTracks().forEach((t) => t.stop());
    } catch (e) {
      console.error("Cleanup error:", e);
    }
  };

  // Process comparison with backend
  const processComparison = useCallback(async (transcribedText: string) => {
    if (!transcribedText.trim()) {
      setIsProcessing(false);
      toast({
        title: "KhÃ´ng nháº­n Ä‘Æ°á»£c giá»ng nÃ³i",
        description: "Vui lÃ²ng thá»­ láº¡i vÃ  Ä‘á»c to, rÃµ rÃ ng hÆ¡n nhÃ©!",
        variant: "destructive",
      });
      return;
    }

    try {
      console.log("ğŸ” Comparing texts...");
      console.log("Expected:", expectedText);
      console.log("Got:", transcribedText);

      // Call API to compare texts
      const result = await ReadingService.compareTexts(expectedText, transcribedText);
      
      // Generate feedback
      const feedbackData = ReadingService.generateFeedback(result.accuracyPercentage, result.wrongWords);
      
      setFeedback({
        accuracy: feedbackData.accuracy,
        errors: feedbackData.errors,
        message: feedbackData.message,
        encouragement: feedbackData.encouragement,
        highlightedText: result.highlightedOriginal,
      });

      // Call callback with results
      if (onRecordingComplete) {
        console.log("âœ… Calling onRecordingComplete with accuracy:", result.accuracyPercentage);
        onRecordingComplete(transcribedText, result.accuracyPercentage, result.wrongWords);
      }

      // Show toast based on accuracy
      if (result.accuracyPercentage >= 80) {
        toast({
          title: feedbackData.message,
          description: `Äá»™ chÃ­nh xÃ¡c: ${result.accuracyPercentage}%`,
        });
      }

    } catch (error) {
      console.error("Error processing comparison:", error);
      toast({
        title: "Lá»—i",
        description: "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch káº¿t quáº£. Vui lÃ²ng thá»­ láº¡i.",
        variant: "destructive",
      });
    } finally {
      setIsProcessing(false);
    }
  }, [expectedText, onRecordingComplete, toast]);

  // Start recording with Web Speech API
  const startWebSpeechRecording = async () => {
    setTranscript("");
    setInterimTranscript("");
    setFeedback(null);

    try {
      // Request microphone permission first
      await navigator.mediaDevices.getUserMedia({ audio: true });
      
      if (recognitionRef.current) {
        recognitionRef.current.start();
        setIsRecording(true);
        toast({ 
          title: "ğŸ¤ Äang ghi Ã¢m", 
          description: "HÃ£y Ä‘á»c to vÃ  rÃµ rÃ ng theo vÄƒn báº£n máº«u!" 
        });
      }
    } catch (error) {
      console.error("Error starting Web Speech:", error);
      toast({
        title: "Lá»—i",
        description: "KhÃ´ng thá»ƒ truy cáº­p microphone. Vui lÃ²ng cho phÃ©p quyá»n truy cáº­p.",
        variant: "destructive",
      });
    }
  };

  // Stop recording with Web Speech API
  const stopWebSpeechRecording = async () => {
    setIsRecording(false);
    setIsProcessing(true);

    try {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    } catch (e) {
      // Ignore
    }

    // Wait a bit for final transcript
    await new Promise(resolve => setTimeout(resolve, 500));

    const finalTranscript = (transcript + ' ' + interimTranscript).trim();
    console.log("Final transcript:", finalTranscript);

    if (finalTranscript) {
      await processComparison(finalTranscript);
    } else {
      setIsProcessing(false);
      toast({
        title: "KhÃ´ng nháº­n Ä‘Æ°á»£c giá»ng nÃ³i",
        description: "Vui lÃ²ng thá»­ láº¡i vÃ  Ä‘á»c to hÆ¡n nhÃ©!",
        variant: "destructive",
      });
    }
  };

  // Start recording with WebSocket (Speechmatics)
  const startWebSocketRecording = async () => {
    setTranscript("");
    setInterimTranscript("");
    setFeedback(null);
    confirmedTextRef.current = "";
    partialTextRef.current = "";

    try {
      console.log("Starting WebSocket recording...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const wsUrl = import.meta.env.VITE_STT_WS_URL || "ws://localhost:4001/ws/stt";
      const ws = new WebSocket(wsUrl);
      wsRef.current = ws;

      ws.onopen = () => {
        console.log("WebSocket connected");
        try {
          const audioCtx = new AudioContext({ sampleRate: 16000 });
          audioCtxRef.current = audioCtx;
          const source = audioCtx.createMediaStreamSource(stream);
          sourceRef.current = source;
          const processor = audioCtx.createScriptProcessor(4096, 1, 1);
          processorRef.current = processor;
          
          processor.onaudioprocess = (e) => {
            const input = e.inputBuffer.getChannelData(0);
            const pcm16 = floatTo16BitPCM(input);
            if (ws.readyState === WebSocket.OPEN && canSendRef.current) {
              ws.send(pcm16);
            }
          };
          
          source.connect(processor);
          processor.connect(audioCtx.destination);
          setIsRecording(true);
          toast({ title: "ğŸ¤ Äang ghi Ã¢m", description: "HÃ£y Ä‘á»c to vÃ  rÃµ rÃ ng nhÃ©!" });
        } catch (err) {
          console.error("Error setting up audio processing:", err);
          toast({ title: "Lá»—i", description: "KhÃ´ng thá»ƒ khá»Ÿi táº¡o xá»­ lÃ½ Ã¢m thanh", variant: "destructive" });
          ws.close();
        }
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          if (data.type === "ready") {
            canSendRef.current = true;
            return;
          }
          if (data.type === "partial") {
            setInterimTranscript(data.text);
            partialTextRef.current = data.text;
          } else if (data.type === "final") {
            setTranscript((prev) => {
              const newText = `${prev} ${data.text}`.trim();
              confirmedTextRef.current = newText;
              return newText;
            });
            setInterimTranscript("");
            partialTextRef.current = "";
          } else if (data.type === "error") {
            console.error("Server reported error:", data.message);
            toast({ title: "Lá»—i STT", description: data.message, variant: "destructive" });
            setIsRecording(false);
            cleanupAudio();
          }
        } catch (e) {
          console.error("Error parsing WS message:", e);
        }
      };

      ws.onerror = () => {
        console.error("WebSocket error - falling back to Web Speech API");
        toast({ 
          title: "KhÃ´ng thá»ƒ káº¿t ná»‘i STT Server", 
          description: "Äang chuyá»ƒn sang phÆ°Æ¡ng thá»©c khÃ¡c...", 
          variant: "destructive" 
        });
        setSttMethod('web');
        cleanupAudio();
      };

      ws.onclose = () => {
        cleanupAudio();
        setIsRecording(false);
      };
    } catch (error) {
      console.error("Error accessing microphone:", error);
      toast({
        title: "Lá»—i",
        description: "KhÃ´ng thá»ƒ truy cáº­p microphone. Vui lÃ²ng cho phÃ©p quyá»n truy cáº­p.",
        variant: "destructive",
      });
    }
  };

  // Stop WebSocket recording
  const stopWebSocketRecording = async () => {
    if (!isRecording) return;
    
    setIsRecording(false);
    setIsProcessing(true);
    canSendRef.current = false;

    try { 
      wsRef.current?.send(JSON.stringify({ type: "stop" })); 
    } catch (e) {
      // Ignore
    }
    
    wsRef.current?.close();
    cleanupAudio();

    await new Promise(resolve => setTimeout(resolve, 800));

    const finalTranscript = confirmedTextRef.current.trim() || partialTextRef.current.trim();
    
    if (finalTranscript) {
      await processComparison(finalTranscript);
    } else {
      setIsProcessing(false);
      toast({
        title: "KhÃ´ng nháº­n Ä‘Æ°á»£c giá»ng nÃ³i",
        description: "Vui lÃ²ng thá»­ láº¡i vÃ  Ä‘á»c to hÆ¡n nhÃ©!",
        variant: "destructive",
      });
    }
  };

  // Unified start/stop functions
  const startRecording = () => {
    if (sttMethod === 'web' && isSpeechRecognitionSupported()) {
      startWebSpeechRecording();
    } else {
      startWebSocketRecording();
    }
  };

  const stopRecording = () => {
    if (sttMethod === 'web') {
      stopWebSpeechRecording();
    } else {
      stopWebSocketRecording();
    }
  };

  const handleRetry = () => {
    setTranscript("");
    setInterimTranscript("");
    setFeedback(null);
    confirmedTextRef.current = "";
    partialTextRef.current = "";
  };

  const [isPlayingTTS, setIsPlayingTTS] = useState(false);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  // Play expected text using OpenAI TTS
  const playExpectedText = async () => {
    if (isPlayingTTS) {
      // Stop current playback
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }
      window.speechSynthesis?.cancel();
      setIsPlayingTTS(false);
      return;
    }

    setIsPlayingTTS(true);
    toast({
      title: "ğŸ”Š Äang táº£i giá»ng Ä‘á»c...",
      description: "Vui lÃ²ng chá» trong giÃ¢y lÃ¡t",
    });

    try {
      const audio = await ReadingService.playText(expectedText);
      if (audio) {
        audioRef.current = audio;
        audio.onended = () => setIsPlayingTTS(false);
        audio.onerror = () => {
          setIsPlayingTTS(false);
          toast({
            title: "Lá»—i",
            description: "KhÃ´ng thá»ƒ phÃ¡t Ã¢m. Äang thá»­ phÆ°Æ¡ng thá»©c khÃ¡c...",
            variant: "destructive",
          });
        };
        toast({
          title: "ğŸ”Š Äang phÃ¡t Ã¢m máº«u",
          description: "HÃ£y láº¯ng nghe vÃ  Ä‘á»c theo nhÃ©!",
        });
      } else {
        // Browser TTS is playing
        setIsPlayingTTS(false);
        toast({
          title: "ğŸ”Š Äang phÃ¡t Ã¢m máº«u",
          description: "Sá»­ dá»¥ng giá»ng Ä‘á»c trÃ¬nh duyá»‡t",
        });
      }
    } catch (error) {
      setIsPlayingTTS(false);
      toast({
        title: "Lá»—i",
        description: "KhÃ´ng thá»ƒ phÃ¡t Ã¢m. Vui lÃ²ng thá»­ láº¡i.",
        variant: "destructive",
      });
    }
  };

  // Play individual word
  const playWord = async (word: string) => {
    try {
      await ReadingService.playText(word);
    } catch (error) {
      // Fallback to browser TTS
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(word);
        utterance.lang = 'vi-VN';
        utterance.rate = 0.8;
        window.speechSynthesis.speak(utterance);
      }
    }
  };

  // Utilities
  const floatTo16BitPCM = (float32Array: Float32Array) => {
    const buffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(buffer);
    for (let i = 0; i < float32Array.length; i++) {
      const s = Math.max(-1, Math.min(1, float32Array[i]));
      view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    }
    return new Uint8Array(buffer);
  };

  const cleanupAudio = () => {
    try {
      processorRef.current?.disconnect();
      sourceRef.current?.disconnect();
      audioCtxRef.current?.close();
      streamRef.current?.getTracks().forEach((t) => t.stop());
    } catch (e) {
      console.error("Audio cleanup error:", e);
    }
  };

  const getAccuracyColor = (accuracy: number) => {
    if (accuracy >= 90) return "bg-success text-success-foreground";
    if (accuracy >= 80) return "bg-green-500 text-white";
    if (accuracy >= 70) return "bg-yellow-500 text-white";
    if (accuracy >= 50) return "bg-orange-500 text-white";
    return "bg-red-500 text-white";
  };

  const currentTranscript = transcript + (interimTranscript ? ' ' + interimTranscript : '');

  return (
    <Card className="p-6 space-y-6">
      <div className="flex justify-between items-center flex-wrap gap-2">
        <h3 className="text-xl font-semibold">ğŸ¤ Ghi Ã¢m giá»ng Ä‘á»c cá»§a báº¡n</h3>
        <div className="flex items-center gap-2">
          {feedback && (
            <Badge className={`text-sm ${getAccuracyColor(feedback.accuracy)}`}>
              Äá»™ chÃ­nh xÃ¡c: {feedback.accuracy}%
            </Badge>
          )}
          <Badge variant="outline" className="text-xs">
            {sttMethod === 'web' ? 'ğŸŒ Web Speech' : 'ğŸ”Œ WebSocket'}
          </Badge>
        </div>
      </div>

      {/* Action buttons */}
      <div className="flex justify-center gap-4 flex-wrap">
        {/* Listen button */}
        <Button
          onClick={playExpectedText}
          variant={isPlayingTTS ? "secondary" : "outline"}
          size="lg"
          className={`rounded-full h-16 w-16 shadow-md hover:shadow-lg transition-all ${isPlayingTTS ? 'animate-pulse' : ''}`}
          title={isPlayingTTS ? "Dá»«ng phÃ¡t" : "Nghe máº«u"}
        >
          {isPlayingTTS ? (
            <Square className="h-5 w-5" />
          ) : (
            <Volume2 className="h-6 w-6" />
          )}
        </Button>

        {/* Record button */}
        <Button
          onClick={isRecording ? stopRecording : startRecording}
          disabled={isProcessing}
          size="lg"
          variant={isRecording ? "destructive" : "default"}
          className="rounded-full h-24 w-24 shadow-lg hover:shadow-xl transition-all"
        >
          {isProcessing ? (
            <Loader2 className="h-8 w-8 animate-spin" />
          ) : isRecording ? (
            <Square className="h-8 w-8" />
          ) : (
            <Mic className="h-8 w-8" />
          )}
        </Button>

        {/* Retry button */}
        {feedback && (
          <Button
            onClick={handleRetry}
            variant="outline"
            size="lg"
            className="rounded-full h-16 w-16 shadow-md hover:shadow-lg transition-all"
            title="Thá»­ láº¡i"
          >
            <RotateCcw className="h-6 w-6" />
          </Button>
        )}
      </div>

      <p className="text-center text-sm text-muted-foreground">
        {isRecording 
          ? "ğŸ”´ Äang ghi Ã¢m... Äá»c theo vÄƒn báº£n máº«u rá»“i nháº¥n Ä‘á»ƒ dá»«ng" 
          : isProcessing 
          ? "â³ Äang phÃ¢n tÃ­ch káº¿t quáº£..." 
          : feedback 
          ? "Nháº¥n ğŸ”„ Ä‘á»ƒ thá»­ láº¡i hoáº·c ğŸ¤ Ä‘á»ƒ Ä‘á»c láº¡i"
          : "Nháº¥n ğŸ”Š Ä‘á»ƒ nghe máº«u, sau Ä‘Ã³ nháº¥n ğŸ¤ Ä‘á»ƒ báº¯t Ä‘áº§u Ä‘á»c"}
      </p>

      {/* Live transcript */}
      {(currentTranscript || isRecording) && !feedback && (
        <div className="bg-muted/30 p-4 rounded-lg">
          <p className="text-sm font-medium mb-2">ğŸ“ Báº¡n Ä‘ang Ä‘á»c:</p>
          <p className="text-sm min-h-[40px]">
            <span className="text-foreground">{transcript}</span>
            {interimTranscript && (
              <span className="text-muted-foreground italic"> {interimTranscript}</span>
            )}
            {isRecording && !currentTranscript && (
              <span className="text-muted-foreground italic animate-pulse">Äang láº¯ng nghe...</span>
            )}
          </p>
        </div>
      )}

      {/* Feedback section */}
      {feedback && (
        <div className="space-y-4 pt-4 border-t animate-fade-in">
          {/* Accuracy banner */}
          <div className={`p-4 rounded-lg ${
            feedback.accuracy >= 80 
              ? "bg-success/10 border-l-4 border-success" 
              : feedback.accuracy >= 50
              ? "bg-warning/10 border-l-4 border-warning"
              : "bg-destructive/10 border-l-4 border-destructive"
          }`}>
            <p className="font-semibold text-lg mb-1">{feedback.message}</p>
            <p className="text-sm text-muted-foreground">{feedback.encouragement}</p>
          </div>

          {/* What you read vs expected */}
          <div className="grid md:grid-cols-2 gap-4">
            <div className="bg-muted/30 p-4 rounded-lg">
              <p className="text-sm font-medium mb-2">ğŸ“– VÄƒn báº£n máº«u:</p>
              <p className="text-sm">{expectedText}</p>
            </div>
            
            {transcript && (
              <div className="bg-blue-50 dark:bg-blue-950/20 p-4 rounded-lg">
                <p className="text-sm font-medium mb-2">ğŸ“ Báº¡n Ä‘Ã£ Ä‘á»c:</p>
                <p className="text-sm italic">{transcript}</p>
              </div>
            )}
          </div>

          {/* Error words */}
          {feedback.errors.length > 0 && (
            <div className="bg-orange-50 dark:bg-orange-950/20 p-4 rounded-lg">
              <p className="font-medium mb-2 text-sm">ğŸ“Œ Nhá»¯ng tá»« cáº§n luyá»‡n thÃªm:</p>
              <div className="flex flex-wrap gap-2">
                {feedback.errors.slice(0, 10).map((word, index) => (
                  <Badge 
                    key={index} 
                    variant="outline" 
                    className="text-sm bg-white dark:bg-gray-800 border-orange-300 cursor-pointer hover:bg-orange-100 active:scale-95 transition-transform"
                    onClick={() => playWord(word)}
                    title="Nháº¥n Ä‘á»ƒ nghe phÃ¡t Ã¢m"
                  >
                    ğŸ”Š {word}
                  </Badge>
                ))}
                {feedback.errors.length > 10 && (
                  <Badge variant="outline" className="text-sm">
                    +{feedback.errors.length - 10} tá»« khÃ¡c
                  </Badge>
                )}
              </div>
              <p className="text-xs text-muted-foreground mt-2">
                ğŸ’¡ Nháº¥n vÃ o tá»« Ä‘á»ƒ nghe phÃ¡t Ã¢m máº«u
              </p>
            </div>
          )}

          {/* Tips for improvement */}
          {feedback.accuracy < 80 && (
            <div className="bg-blue-50 dark:bg-blue-950/20 p-4 rounded-lg text-sm">
              <p className="font-medium mb-2">ğŸ’¡ Gá»£i Ã½ cáº£i thiá»‡n:</p>
              <ul className="list-disc list-inside space-y-1 text-muted-foreground">
                <li>Nháº¥n ğŸ”Š Ä‘á»ƒ nghe cÃ¡ch Ä‘á»c máº«u trÆ°á»›c khi thá»­ láº¡i</li>
                <li>Äá»c cháº­m vÃ  rÃµ rÃ ng tá»«ng tá»«</li>
                <li>ChÃº Ã½ phÃ¡t Ã¢m Ä‘Ãºng cÃ¡c tá»« Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u mÃ u cam</li>
                <li>Luyá»‡n táº­p cÃ¡c tá»« khÃ³ báº±ng cÃ¡ch nháº¥n vÃ o tá»«ng tá»« Ä‘á»ƒ nghe</li>
              </ul>
            </div>
          )}

          {/* Celebration for high accuracy */}
          {feedback.accuracy >= 90 && (
            <div className="bg-success/10 p-4 rounded-lg text-center">
              <p className="text-2xl mb-2">ğŸ‰ ğŸŒŸ ğŸ†</p>
              <p className="font-semibold text-success">Tuyá»‡t vá»i! Báº¡n Ä‘á»c ráº¥t xuáº¥t sáº¯c!</p>
            </div>
          )}
        </div>
      )}
    </Card>
  );
};
